{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LPUUr_q8f4C"
      },
      "source": [
        "Google Colab에서 Google Drive를 마운트해서 드라이브 내 파일들에 접근 허용\n",
        "`with open('경로', 'r') as _ : ` 등으로 파일 읽기 가능"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "g5of12mN8mVr"
      },
      "outputs": [],
      "source": [
        "# 계산, 통계에 자주 사용되는 Numpy 라이브러리\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LEOJ3oxx9GHO"
      },
      "outputs": [],
      "source": [
        "# Python 정규표현식 모듈\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_y57PsQK9uRG"
      },
      "source": [
        "## 1. 입력데이터 전처리 작업\n",
        "**1.한글, 숫자, 영어를 제외한 글자는 모두 '_'로 치환**\n",
        "\n",
        "[^...] : 부정 문자 클래스, 괄호 안의 문자들이 아닌 것들을 매칭\n",
        "\n",
        "0-9 : 아라비아 숫자 (0~9)\n",
        "\n",
        "a-zA-Z : 영어 알파벳 (소문자 + 대문자)\n",
        "\n",
        "\\u3131-\\u3163 : 한글 자모 범위 (ㄱ ~ ㅣ)\n",
        "\n",
        "\\uac00-\\ud7a3 : 완성형 한글 (가 ~ 힣)\n",
        "\n",
        "**2. 언더바가 하나 이상일 경우 언더바 하나로 치환**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YNGG_wcP9GrM"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(text):\n",
        "\n",
        "    \"\"\"\n",
        "    input_text = '아 이 영화 스토리랑 연기랑;; 개ㅐㅐ노잼^^!!!!! 인데 왜 9점임???'\n",
        "    output_text = '$아_이_영화_스토리랑_연기랑_개ㅐㅐ노잼_인데_왜_9점임_$'\n",
        "    \"\"\"\n",
        "\n",
        "    non_alpha_numeric_hangul = re.compile('[^0-9a-zA-Z\\u3131-\\u3163\\uac00-\\ud7a3]')\n",
        "    sentense_separator = '$'\n",
        "\n",
        "    # text의 대상 문자열을 _ 로 변경\n",
        "    t = non_alpha_numeric_hangul.sub('_', text)\n",
        "\n",
        "    # _가 2개 이상일 경우, 하나로 치환\n",
        "    text = re.sub(r'_+', '_', t)\n",
        "    return f'{sentense_separator}{text}{sentense_separator}'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_N0DdDFF5fe"
      },
      "source": [
        "# 2. 입력 파일 형식에 맞춰 data와 target 값 읽어오기\n",
        "---\n",
        "\n",
        "**id\tdocument\tlabel**<br>\n",
        "6270596\t굳 ㅋ\t1 <br>\n",
        "9274899\tGDNTOPCLASSINTHECLUB\t0 <br>\n",
        "8544678\t뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아\t0<br>\n",
        "6825595\t지루하지는 않은데 완전 막장임... 돈주고 보기에는....\t0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9jlLvUpz92gq"
      },
      "outputs": [],
      "source": [
        "def prepare_data_file(FILE_PATH):\n",
        "\n",
        "    # 경로로 파일 열기\n",
        "    with open(FILE_PATH) as f:\n",
        "        lines = f.read().split('\\n') # 한 줄씩 읽어오기\n",
        "\n",
        "    data, target = [], []\n",
        "    for l in lines[1:]: # 첫째 줄은 컬럼명이라 읽어오지 않음\n",
        "        try:\n",
        "            _, text, label = l.strip().split('\\t') # 탭으로 구분\n",
        "        except ValueError:\n",
        "            pass\n",
        "        text = text.strip() # text 내부의 공백 제거\n",
        "        if text == '' : continue # 공백 데이터는 학습 데이터로 사용하지 않음\n",
        "        data.append(preprocess_text(text))\n",
        "        target.append(int(label))\n",
        "\n",
        "    return data, target"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keuKlFCZ32E2"
      },
      "source": [
        "# 3. Bigram feature를 추출하여 feature_dict으로 만들어서 리턴\n",
        "MAX_FEATURES : 사용할 feature 개수\n",
        "\n",
        "_feature_dict는 ML 벡터화에 쓰이는 biagram -> 숫자 맵핑테이블_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Dwa0P8QW38Jg"
      },
      "outputs": [],
      "source": [
        "def extract_features(data, MAX_FEATURES):\n",
        "\n",
        "    FEATURES = dict()\n",
        "\n",
        "    \"\"\"\n",
        "    bigram을 생성하고 등장 빈도수 체크\n",
        "    \"\"\"\n",
        "\n",
        "    for line in data:\n",
        "        uni_list = list(line)\n",
        "        bi_list = [''.join(uni_list[z:z+2]) for z in range(0, len(uni_list)-1)]\n",
        "\n",
        "        for bigram in bi_list:\n",
        "\n",
        "            if bigram in FEATURES: # 빈도수 누적\n",
        "                FEATURES[bigram] += 1\n",
        "            else:\n",
        "                FEATURES[bigram] = 1\n",
        "\n",
        "    features_list = [(b, c) for (b, c) in FEATURES.items()]\n",
        "    features_list.sort(reverse=True, key=lambda z:z[1]) # count 순으로 내림차순 정렬\n",
        "\n",
        "    features_dict = dict()\n",
        "    for (idx, (b, c)) in enumerate(features_list[:MAX_FEATURES]):\n",
        "        features_dict[b] = idx\n",
        "\n",
        "    return features_dict\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPbWiDXaDsjT"
      },
      "source": [
        "# 4. 입력 문장을 고정된 크기의 Feature  Vector로 변환하여 ML 학습에 사용할 입력 벡터 생성\n",
        "Bigram 기반의 이진 벡터"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "WvCq04Xz8nPw"
      },
      "outputs": [],
      "source": [
        "def make_feature_vector(feature_set, data, target):\n",
        "\n",
        "    # 기본 벡터 템플릿 생성 [0,0,0,0, ..., 0]\n",
        "    fv_base = [0 for _ in range(0, len(feature_set))]\n",
        "    feature_list = []\n",
        "\n",
        "    for (x, label) in zip(data, target):\n",
        "        uni_list = list(x)\n",
        "        fv = fv_base[:]\n",
        "        bi_list = [''.join(uni_list[z:z+2]) for z in range(0, len(uni_list)-1)]\n",
        "\n",
        "        # one-hot 방식\n",
        "        for bigram in bi_list:\n",
        "            if bigram in feature_set:\n",
        "                fv[feature_set[bigram]] = 1\n",
        "        feature_list.append(fv + [label])\n",
        "    feature_list = np.array(feature_list)\n",
        "\n",
        "    # ML시 train/test bias를 방지하기 위해 셔플\n",
        "    np.random.shuffle(feature_list)\n",
        "\n",
        "    return feature_list[:, :-1], feature_list[:, -1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bV4EuvO2MAIR"
      },
      "source": [
        "## 학습데이터, 평가데이터 읽어오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHFgopnZDwoF",
        "outputId": "f2e43cab-b39e-400d-d911-51a0c9b8e70c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prepare_data_file START...\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '.ratings_train.txt'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[8], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m TEST_FILE  \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.ratings_test.txt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprepare_data_file START...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m train_data, train_target \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_data_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTRAIN_FILE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m test_data, test_target \u001b[38;5;241m=\u001b[39m prepare_data_file(TEST_FILE)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprepare_data_file END...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "Cell \u001b[0;32mIn[5], line 4\u001b[0m, in \u001b[0;36mprepare_data_file\u001b[0;34m(FILE_PATH)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprepare_data_file\u001b[39m(FILE_PATH):\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# 경로로 파일 열기\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mFILE_PATH\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      5\u001b[0m         lines \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m# 한 줄씩 읽어오기\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     data, target \u001b[38;5;241m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/Library/Python/3.12/lib/python/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '.ratings_train.txt'"
          ]
        }
      ],
      "source": [
        "TRAIN_FILE = 'ratings_train.txt'\n",
        "TEST_FILE  = 'ratings_test.txt'\n",
        "\n",
        "print('prepare_data_file START...')\n",
        "train_data, train_target = prepare_data_file(TRAIN_FILE)\n",
        "test_data, test_target = prepare_data_file(TEST_FILE)\n",
        "print('prepare_data_file END...')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9oPdv6vMVEv"
      },
      "source": [
        "## 학습데이터로부터 MAX_FEATURES개의 Bigram Feature 추출"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXDYqR0BMU2R",
        "outputId": "7810fcd0-f117-4839-e133-0792e09b798f"
      },
      "outputs": [],
      "source": [
        "print('extract_features START...')\n",
        "MAX_FEATURES = 1000\n",
        "feature_set = extract_features(train_data, MAX_FEATURES)\n",
        "with open('features.out', 'w', encoding='utf-8') as fo:\n",
        "    fo.write('\\n'.join([x+str(idx) for x, idx in feature_set.items()]))\n",
        "\n",
        "print('extract_features END...')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOs4cUyjNLEy"
      },
      "source": [
        "## 입력 파일을 고정된 크기의 feature vector로 변환"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSW0KegPNO5m",
        "outputId": "416916ea-d171-47a7-be11-dd83d9022cb5"
      },
      "outputs": [],
      "source": [
        "print('make_feature_vector START...')\n",
        "x_train, y_train = make_feature_vector(feature_set, train_data, train_target)\n",
        "x_test, y_test = make_feature_vector(feature_set, test_data, test_target)\n",
        "print('make_feature_vector END...')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFlEl1jNPEuo"
      },
      "source": [
        "## ML 모델 생성 및 학습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMOTRI0CNpUk",
        "outputId": "080a7bad-a933-4185-9fd3-a8b7a79621e1"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "print('train START...')\n",
        "model = MultinomialNB()\n",
        "model.fit(x_train, y_train)\n",
        "print('train END...')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EER9iC27PXiQ"
      },
      "source": [
        "## 정확도 평가"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvTvuRM7PVfd",
        "outputId": "7540c907-bdc1-458c-950f-2532ed418ff2"
      },
      "outputs": [],
      "source": [
        "print('eval START...')\n",
        "print(f'TRAIN ACCURACY : {model.score(x_train, y_train):3f}')\n",
        "print(f'TEST SCORE : {model.score(x_test, y_test):3f}')\n",
        "print('evel END...')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkqxKNUHQItd"
      },
      "source": [
        "## 실행"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhgBDqRMPr3V",
        "outputId": "6afe9517-845d-4034-88b8-ecc545cbe42a"
      },
      "outputs": [],
      "source": [
        "# 예측 실패\n",
        "text = '어쩌다 이 영화를 보게 되었는지.. 함꼐 본 사람은 좋았지만 영화는 그를 잊을만큼 정말 별로였어요'\n",
        "text = preprocess_text(text)\n",
        "x_test, _ = make_feature_vector(feature_set, [text], [None])\n",
        "result = model.predict(x_test)\n",
        "print(text, '==>', ['Negative','Positive'][result[0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jj0_JYYhQgyR",
        "outputId": "7e4bfa2a-fdd7-4e82-ac3e-67db388d4bcc"
      },
      "outputs": [],
      "source": [
        "# 예측 성공\n",
        "text = '연기도 재밌고 존잼!'\n",
        "text = preprocess_text(text)\n",
        "x_test, _ = make_feature_vector(feature_set, [text], [None])\n",
        "result = model.predict(x_test)\n",
        "print(text, '==>', ['Negative','Positive'][result[0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOC-xwQWQmTr",
        "outputId": "d0be7eea-2046-4588-a2ee-9feac856df7f"
      },
      "outputs": [],
      "source": [
        "# 예측 성공\n",
        "text = 'ㅈㄴ별로임 진짜... 하.... 돈 아까워'\n",
        "text = preprocess_text(text)\n",
        "x_test, _ = make_feature_vector(feature_set, [text], [None])\n",
        "result = model.predict(x_test)\n",
        "print(text, '==>', ['Negative','Positive'][result[0]])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
